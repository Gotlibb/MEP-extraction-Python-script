{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Made by Gleb Perevoznyuk, HSE. 2024\n",
    "## All rights reserved. Do not modify or remove this notice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation, imports and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For setting up your environment, you only need to install these packages once per machine and environment.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17907,
     "status": "ok",
     "timestamp": 1721826434215,
     "user": {
      "displayName": "Motor Control Group HSE",
      "userId": "15094889534527393586"
     },
     "user_tz": -180
    },
    "id": "8w1zBehzulvC",
    "outputId": "86698dee-abd0-45e3-cd94-4a57ec60cfd1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install os-sys\n",
    "# !pip install openpyxl\n",
    "# !pip install pandas\n",
    "# !pip install pathlib  \n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install scipy\n",
    "# !pip install mne\n",
    "# !pip install screeninfo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each session, you need to rerun these import statements to ensure all necessary libraries are loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import mne\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_participant_condition_dict(folder_path):\n",
    "    '''\n",
    "    Creates a dictionary where the keys are participant names, and the values are nested dictionaries. \n",
    "    These nested dictionaries have conditions as keys, and each condition has a nested dictionary with the file path.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing .vhdr files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are participant names, and the values are nested dictionaries \n",
    "          with conditions as keys and a nested dictionary containing the file path.\n",
    "\n",
    "    Example:\n",
    "    Input:\n",
    "    The specified folder contains the following files:\n",
    "    MaSh_13_s1_B_1.vhdr\n",
    "    MaSh_13_s1_BM_1.vhdr\n",
    "\n",
    "    Output:\n",
    "    {\n",
    "        'MaSh_13_s1': {\n",
    "            'B_1': {'path': 'C:\\\\path\\\\to\\\\folder\\\\MaSh_13_s1_B_1.vhdr'},\n",
    "            'BM_1': {'path': 'C:\\\\path\\\\to\\\\folder\\\\MaSh_13_s1_BM_1.vhdr'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Description:\n",
    "    1. The function recursively iterates through all files and directories in the specified folder.\n",
    "    2. For each file with a .vhdr extension that does not end with 'ttt.vhdr', it splits the file name into parts.\n",
    "    3. The participant name is formed from the first two parts of the file name.\n",
    "    4. The condition is determined from the third and fourth parts of the file name if they contain 'B' but not 'BM'. \n",
    "       Otherwise, the condition is determined only from the third part.\n",
    "    5. If the participant name is not already in the dictionary, a new nested dictionary for conditions is created.\n",
    "    6. If the condition is not already in the nested dictionary, a new dictionary for file path is created.\n",
    "    7. The file path is stored in the nested dictionary under the 'path' key.\n",
    "    '''\n",
    "\n",
    "    participant_dict = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.vhdr') and not file_name.endswith('ttt.vhdr'):\n",
    "                parts = file_name.split('_')\n",
    "                participant_name = parts[0] + '_' + parts[1]\n",
    "                if 'B' in parts[3] and not 'BM' in parts[3]:\n",
    "                    condition = parts[3] + '_' + parts[4].split('.')[0]\n",
    "                else: \n",
    "                    condition = parts[3].split('.')[0]\n",
    "                \n",
    "                if participant_name not in participant_dict:\n",
    "                    participant_dict[participant_name] = {}\n",
    "\n",
    "                participant_dict[participant_name][condition] = {'path': os.path.join(root, file_name)}\n",
    "\n",
    "    return participant_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_and_filtrate(vhdr_file):\n",
    "    \"\"\"\n",
    "    Loads and preprocesses a BrainVision data file.\n",
    "\n",
    "    Parameters:\n",
    "    vhdr_file (str): Path to the BrainVision .vhdr file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - raw (mne.io.Raw): The raw data object loaded from the BrainVision file.\n",
    "        - sfreq (float): The sampling frequency of the data.\n",
    "        - ch_list (list of str): A list of channel names in the data.\n",
    "    \"\"\"\n",
    "    raw = mne.io.read_raw_brainvision(vhdr_file, preload=True)\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    ch_list = raw.ch_names\n",
    "    return raw, sfreq, ch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrations(raw, fs):\n",
    "    \"\"\"\n",
    "    Applies high-pass and notch filters to the raw EEG data.\n",
    "\n",
    "    Parameters:\n",
    "    raw (mne.io.Raw): The raw EEG data object.\n",
    "    fs (float): The sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    mne.io.Raw: The filtered raw EEG data object.\n",
    "    \"\"\"\n",
    "    # Define filter parameters\n",
    "    high_cutoff = 15  \n",
    "    order = 2\n",
    "    notch_freq_range = [48, 52]\n",
    "\n",
    "    # Create Butterworth high-pass filter\n",
    "    b, a = butter(order, high_cutoff / (0.5 * fs), btype='high')\n",
    "    \n",
    "    # Apply high-pass filter\n",
    "    raw_data = raw.get_data()\n",
    "    filtered_data = filtfilt(b, a, raw_data, axis=1)\n",
    "    \n",
    "    # Create Butterworth band-stop (notch) filter\n",
    "    br, ar = butter(order, [notch_freq_range[0] / (0.5 * fs), notch_freq_range[1] / (0.5 * fs)], btype='bandstop')\n",
    "    \n",
    "    # Apply band-stop filter\n",
    "    filtered_data = filtfilt(br, ar, filtered_data, axis=1)\n",
    "    \n",
    "    # Create new Raw object with filtered data\n",
    "    info = raw.info\n",
    "    raw_filtered = mne.io.RawArray(filtered_data, info)\n",
    "\n",
    "    raw_filtered.set_annotations(raw.annotations)\n",
    "    \n",
    "    # Transfer events\n",
    "    events, _ = mne.events_from_annotations(raw)\n",
    "    event_id = {99999:'New Segment/', 128:'Stimulus/S128'}\n",
    "    annotations = mne.annotations_from_events(events, fs, event_id)\n",
    "    raw_filtered.set_annotations(annotations)\n",
    "    \n",
    "    return raw_filtered\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_selected_channels(raw, raw_filtered, channel_names, first_label, second_label, participant_name, condition_name):\n",
    "    \"\"\"\n",
    "    Plots the original and filtered signals for selected channels.\n",
    "\n",
    "    Parameters:\n",
    "    raw (mne.io.Raw): The raw EEG data object.\n",
    "    raw_filtered (mne.io.Raw): The filtered EEG data object.\n",
    "    channel_names (list of str): List of channel names to plot.\n",
    "    first_label (str): Label for the original signal.\n",
    "    second_label (str): Label for the filtered signal.\n",
    "    participant_name (str): Name of the participant.\n",
    "    condition_name (str): Condition name.\n",
    "\n",
    "    \"\"\"\n",
    "    times = raw.times\n",
    "    num_channels = len(channel_names)\n",
    "\n",
    "    plt.figure(figsize=(15, num_channels * 2))\n",
    "    \n",
    "    for i, channel_name in enumerate(channel_names):\n",
    "        original_data = raw.get_data(picks=channel_name)[0]\n",
    "        clean_data = raw_filtered.get_data(picks=channel_name)[0]\n",
    "\n",
    "        plt.subplot(num_channels, 1, i + 1)\n",
    "        plt.plot(times, original_data, label=first_label)\n",
    "        plt.plot(times, clean_data, label=second_label, linestyle='--')\n",
    "        plt.title(f'{participant_name} - {condition_name} - Signal Before and After Filtering - {channel_name}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def picking_channel(raw, ch_list):\n",
    "    \"\"\"\n",
    "    Creates a dictionary of raw data objects for each specified channel.\n",
    "\n",
    "    Parameters:\n",
    "    raw (mne.io.Raw): The raw EEG data object.\n",
    "    ch_list (list of str): List of channel names to pick from the raw data.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are channel names and values are corresponding raw data objects containing only that channel's data.\n",
    "    \"\"\"\n",
    "    dict_ch_data = {}\n",
    "    for channel_name in ch_list:\n",
    "        raw_copy = raw.copy()\n",
    "        raw_copy.pick([channel_name])  \n",
    "        dict_ch_data[channel_name] = raw_copy\n",
    "        \n",
    "    return dict_ch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoching_by_channel(channel_data_dict):\n",
    "    \"\"\"\n",
    "    Creates epochs for each channel based on TMS pulse events.\n",
    "\n",
    "    Parameters:\n",
    "    channel_data_dict (dict): A dictionary where keys are channel names and values are corresponding raw data objects.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are channel names and values are epoch objects created from the raw data.\n",
    "    \"\"\"\n",
    "    epoched_dict = {}\n",
    "    for channel, ch_data in channel_data_dict.items():\n",
    "        ch_events, ch_events_id = mne.events_from_annotations(ch_data)\n",
    "        ch_events_id = {'TMS pulse': 128}\n",
    "        ch_epochs = mne.Epochs(ch_data, ch_events, ch_events_id, tmin=-0.5, tmax=1, baseline=(-0.1, -0.01), preload=True)\n",
    "        epoched_dict[channel] = ch_epochs\n",
    "    return epoched_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_participant_data(participant_dict):\n",
    "    \"\"\"\n",
    "    Processes the EEG data for each participant and condition.\n",
    "    The processing includes loading, filtering, epoching, and storing the data.\n",
    "\n",
    "    Parameters:\n",
    "    participant_dict (dict): A dictionary with participant names as keys and conditions as nested dictionaries.\n",
    "                             Each condition contains the path to the corresponding .vhdr file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary structure similar to the input, but with additional keys for the sampling frequency (sfreq),\n",
    "          channel list (ch_list), and epochs for each channel.\n",
    "    \"\"\"\n",
    "    raw_data_dict = {}\n",
    "\n",
    "    for part_name, conditions in participant_dict.items():\n",
    "        for cond_name, info in conditions.items():\n",
    "            # Load and filter the data\n",
    "            path = info['path']\n",
    "            raw, sfreq, ch_list = upload_and_filtrate(path)\n",
    "            \n",
    "            # Update the dictionary with metadata\n",
    "            participant_dict[part_name][cond_name]['sfreq'] = sfreq\n",
    "            participant_dict[part_name][cond_name]['ch_list'] = ch_list\n",
    "            \n",
    "            # Apply filtering to the raw data\n",
    "            raw_filtered = filtrations(raw, sfreq)\n",
    "            \n",
    "            # Store raw and filtered data for plotting later\n",
    "            raw_data_dict[(part_name, cond_name)] = (raw, raw_filtered, ch_list)\n",
    "            \n",
    "            # Create epochs for each channel directly\n",
    "            epoched_dict = epoching_by_channel({ch: raw_filtered.copy().pick([ch]) for ch in ch_list})\n",
    "            participant_dict[part_name][cond_name]['epochs'] = epoched_dict\n",
    "    \n",
    "    # Plot the original and filtered signals after processing all data\n",
    "    #for (part_name, cond_name), (raw, raw_filtered, ch_list) in raw_data_dict.items():\n",
    "        #plot_selected_channels(raw, raw_filtered, ch_list, 'Original signal', 'Filtered signal', part_name, cond_name)\n",
    "\n",
    "    return participant_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p2p_amplitude(epoch_data):\n",
    "    \"\"\"\n",
    "    Calculates the peak-to-peak amplitude of the transmitted epoch data.\n",
    "    \n",
    "    Parameters:\n",
    "    epoch_data (array): array of signal data.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (peak-to-peak amplitude, peak value, valley value, peak time, valley time)\n",
    "    \"\"\"\n",
    "    peaks, _ = find_peaks(epoch_data)\n",
    "    troughs, _ = find_peaks(-epoch_data)\n",
    "    \n",
    "    p2p_amplitude = 0\n",
    "    peak_val, trough_val, peak_time, trough_time = None, None, None, None\n",
    "    if peaks.size > 0 and troughs.size > 0:\n",
    "        peak_val = epoch_data[peaks].max()\n",
    "        trough_val = epoch_data[troughs].min()\n",
    "        p2p_amplitude = float(peak_val) - float(trough_val)\n",
    "        peak_time = peaks[np.argmax(epoch_data[peaks])]\n",
    "        trough_time = troughs[np.argmin(epoch_data[troughs])]\n",
    "    \n",
    "    return p2p_amplitude, peak_val, trough_val, peak_time, trough_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from screeninfo import get_monitors\n",
    "\n",
    "def plot_epochs_for_all_channels(epoched_dict, ch_list, condition, time_window=(-0.5, 0.5), auto_accept=False):\n",
    "    \"\"\"\n",
    "    Plots all channels for each epoch iteratively with the specified time window.\n",
    "\n",
    "    Parameters:\n",
    "    epoched_dict (dict): Dictionary containing epoched data.\n",
    "    ch_list (list of str): List of channel names.\n",
    "    condition (str): The condition name, automatically passed from the dictionary.\n",
    "    time_window (tuple): Time window to display on the x-axis.\n",
    "    auto_accept (bool): If True, automatically accept all epochs; if False, prompt for user input.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the peak-to-peak amplitudes for each channel and epoch.\n",
    "    \"\"\"\n",
    "    p2p_data = {muscle: [] for muscle in epoched_dict.keys()}\n",
    "    \n",
    "    # Get screen dimensions\n",
    "    monitor = get_monitors()[0]  \n",
    "    screen_width, screen_height = monitor.width, monitor.height\n",
    "    \n",
    "    # Calculate figure size based on screen dimensions\n",
    "    fig_width = screen_width / 100  # Adjust scale factor as needed\n",
    "    fig_height = screen_height / 100\n",
    "    \n",
    "    for epoch_idx in range(len(epoched_dict[ch_list[0]])):\n",
    "        fig, axs = plt.subplots(len(ch_list) // 2 + len(ch_list) % 2, 2, figsize=(fig_width, fig_height), sharex=True)\n",
    "        fig.suptitle(f'Epoch {epoch_idx + 1} - Condition: {condition}', fontsize=16)\n",
    "        print(f'Epoch {epoch_idx + 1} - Condition: {condition}')\n",
    "        \n",
    "        for i, (ax, channel_name) in enumerate(zip(axs.flat, ch_list)):\n",
    "            epoch_data = epoched_dict[channel_name].get_data(units='uV')[epoch_idx, 0, :]\n",
    "            times = epoched_dict[channel_name].times\n",
    "            \n",
    "            p2p_amplitude, peak_val, trough_val, peak_time, trough_time = calculate_p2p_amplitude(epoch_data)\n",
    "\n",
    "            ax.plot(times, epoch_data, label=f'{channel_name} - Epoch {epoch_idx + 1}')\n",
    "            if peak_val is not None and trough_val is not None:\n",
    "                ax.plot(times[peak_time], peak_val, 'ro')  # Red dot for the peak\n",
    "                ax.plot(times[trough_time], trough_val, 'yo')  # Yellow dot for the though\n",
    "                ax.axvline(times[peak_time], color='r', linestyle='--') # Red line for the peak\n",
    "                ax.axvline(times[trough_time], color='y', linestyle='--') # Yellow line for the though\n",
    "                if isinstance(p2p_amplitude, (int, float)):\n",
    "                    ax.text(0.5, 0.8, f'P2P Amplitude: {p2p_amplitude:.2f}', \n",
    "                            transform=ax.transAxes, fontsize=10, verticalalignment='top', \n",
    "                            bbox=dict(facecolor='white', alpha=0.8))\n",
    "                else:\n",
    "                    ax.text(0.5, 0.8, f'P2P Amplitude: {p2p_amplitude}', \n",
    "                            transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "                            bbox=dict(facecolor='white', alpha=0.8))\n",
    "            ax.axvline(x=0, color='k', linestyle='-', label='TMS Pulse')\n",
    "            ax.set_xlim(time_window)\n",
    "            ax.set_title(channel_name)\n",
    "            ax.set_xlabel('Time (s)')\n",
    "            ax.set_ylabel('Amplitude')\n",
    "\n",
    "            ax.legend(loc='upper left')\n",
    "\n",
    "            yticks = ax.get_yticks()\n",
    "            ax.set_yticks(yticks[1:])\n",
    "\n",
    "            xticks = ax.get_xticks()\n",
    "            ax.set_xticks(xticks[1:])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        if auto_accept:\n",
    "            epoch_accepted = '1'\n",
    "        else:\n",
    "            epoch_accepted = input(\"Enter 0 to reject this epoch or 1 to accept this epoch: \")\n",
    "        \n",
    "        for channel_name in ch_list:\n",
    "            if epoch_accepted == '1':\n",
    "                epoch_data = epoched_dict[channel_name].get_data(units='uV')[epoch_idx, 0, :]\n",
    "                p2p_amplitude, _, _, _, _ = calculate_p2p_amplitude(epoch_data)\n",
    "                p2p_data[channel_name].append(p2p_amplitude)\n",
    "            else:\n",
    "                p2p_data[channel_name].append(float('nan'))\n",
    "\n",
    "    p2p_df = pd.DataFrame(p2p_data)\n",
    "    p2p_df.index.name = condition  \n",
    "    \n",
    "    return p2p_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_epochs_and_plot(participant_data):\n",
    "    \"\"\"\n",
    "    Processes the epochs for each channel within each condition for each participant.\n",
    "    It calculates the peak-to-peak amplitude for each epoch and plots the results.\n",
    "\n",
    "    Parameters:\n",
    "    participant_data (dict): The dictionary containing participant EEG data, conditions, and epochs.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the peak-to-peak amplitude DataFrames for each condition of each participant.\n",
    "    \"\"\"\n",
    "    p2p_amplitude_results = {}\n",
    "\n",
    "    for participant, conditions in participant_data.items():\n",
    "        p2p_amplitude_results[participant] = {}\n",
    "\n",
    "        for condition, info in conditions.items():\n",
    "            epochs = info['epochs']\n",
    "            ch_list = info['ch_list']\n",
    "            \n",
    "            p2p_df = plot_epochs_for_all_channels(epochs, ch_list, condition)\n",
    "            \n",
    "            p2p_amplitude_results[participant][condition] = p2p_df\n",
    "    \n",
    "    return p2p_amplitude_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_ptp_amplitude_to_excel(processed_data, folder_path):\n",
    "    \"\"\"\n",
    "    Saves the peak-to-peak amplitude data for each participant and condition into an Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    processed_data (dict): Dictionary containing the processed data for each participant and condition.\n",
    "    folder_path (str): Path to the folder where the Excel file will be saved.\n",
    "    \"\"\"\n",
    "    participant_name = list(processed_data.keys())[0]\n",
    "    output_file = os.path.join(folder_path, f'{participant_name}_All_ptp_amplitude.xlsx')\n",
    "\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        for part_name, conditions in processed_data.items():\n",
    "            combined_df = pd.DataFrame()\n",
    "\n",
    "            for cond_name, df in conditions.items():\n",
    "                if isinstance(df, pd.DataFrame):\n",
    "                    print(f\"Processing {part_name} - {cond_name}\")\n",
    "                    if isinstance(df.columns, pd.MultiIndex):\n",
    "                        condition_df = df\n",
    "                    else:\n",
    "                        df.columns = pd.MultiIndex.from_product([[cond_name], df.columns])\n",
    "                        condition_df = df\n",
    "                    \n",
    "                    combined_df = pd.concat([combined_df, condition_df], axis=1)\n",
    "                else:\n",
    "                    print(f\"No DataFrame found for {part_name} - {cond_name}\")\n",
    "\n",
    "            if not combined_df.empty:\n",
    "                combined_df.to_excel(writer, sheet_name=part_name)\n",
    "            else:\n",
    "                print(f\"No data to write for {part_name}\")\n",
    "\n",
    "    print(f'Saved P2P amplitudes to {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Run all the code below to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\himik\\OneDrive\\gotlibb\\HSE\\mep_extr\\data\\MaSh_13' #!!! CHANGE !!!\n",
    "participant_dict = create_participant_condition_dict(folder_path)\n",
    "\n",
    "participant_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_data = process_participant_data(participant_dict)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2p_results = process_epochs_and_plot(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2p_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_ptp_amplitude_to_excel(p2p_results, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPC+4i/IhDkliukJfri8ly3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
